# GAIA-BT System Architecture Documentation v3.84

## ğŸ“‹ ì‹œìŠ¤í…œ ê°œìš”

GAIA-BTëŠ” ì‹ ì•½ê°œë°œ ì „ë¬¸ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ë¡œ, ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ í™•ì¥ ê°€ëŠ¥í•˜ê³  ëª¨ë“ˆí™”ëœ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. Ollama LLM, MCP(Model Context Protocol), RAG(Retrieval-Augmented Generation), ê·¸ë¦¬ê³  Reasoning RAG ì‹œìŠ¤í…œì„ í†µí•©í•˜ì—¬ í¬ê´„ì ì¸ ì—°êµ¬ ì§€ì› ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ—ï¸ ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "Frontend Layer"
        WEB[WebUI - Next.js]
        CLI[CLI Interface]
        API_CLIENT[External API Clients]
    end
    
    subgraph "API Gateway Layer"
        FASTAPI[FastAPI Server<br/>Port 8000]
        WS[WebSocket Manager]
        CORS[CORS Middleware]
    end
    
    subgraph "Core Services"
        CHAT[Chat Service]
        SYSTEM[System Service]
        SESSION[Session Manager]
    end
    
    subgraph "AI & RAG Layer"
        OLLAMA[Ollama LLM<br/>Port 11434]
        RAG[RAG Pipeline]
        REASONING[Reasoning RAG<br/>v3.84+]
        RERANKER[BGE Reranker]
    end
    
    subgraph "Data Layer"
        MILVUS[Milvus Vector DB<br/>Port 19530]
        FEEDBACK[Feedback Store]
        CONTEXT[Context Store]
    end
    
    subgraph "External Services"
        MCP[MCP Servers]
        DRUGBANK[DrugBank API]
        PUBMED[PubMed API]
        BIOMCP[BioMCP Server]
    end
    
    subgraph "Management Layer"
        ATTU[Attu UI<br/>Port 3000]
        SWAGGER[Swagger UI<br/>Port 8000/docs]
        MONITORING[System Monitoring]
    end
    
    WEB --> FASTAPI
    CLI --> FASTAPI
    API_CLIENT --> FASTAPI
    
    FASTAPI --> CHAT
    FASTAPI --> SYSTEM
    FASTAPI --> SESSION
    FASTAPI --> WS
    
    CHAT --> OLLAMA
    CHAT --> RAG
    CHAT --> REASONING
    
    RAG --> MILVUS
    RAG --> RERANKER
    REASONING --> MILVUS
    REASONING --> RERANKER
    
    SYSTEM --> MCP
    MCP --> DRUGBANK
    MCP --> PUBMED
    MCP --> BIOMCP
    
    FEEDBACK --> MILVUS
    CONTEXT --> MILVUS
    
    ATTU --> MILVUS
    SWAGGER --> FASTAPI
```

## ğŸ”§ í•µì‹¬ ì»´í¬ë„ŒíŠ¸

### 1. Frontend Layer

#### WebUI (Next.js)
- **í¬íŠ¸**: 3003
- **ê¸°ìˆ **: Next.js 15, TypeScript, Tailwind CSS
- **ì£¼ìš” ê¸°ëŠ¥**:
  - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ…
  - ëª¨ë“œ ì „í™˜ (ì¼ë°˜ â†” ë”¥ë¦¬ì„œì¹˜)
  - ì‘ë‹µ í”¼ë“œë°± ì‹œìŠ¤í…œ
  - ë°˜ì‘í˜• ë””ìì¸

```typescript
// í•µì‹¬ ì»´í¬ë„ŒíŠ¸ êµ¬ì¡°
src/
â”œâ”€â”€ app/              # App Router
â”œâ”€â”€ components/       # React ì»´í¬ë„ŒíŠ¸
â”‚   â”œâ”€â”€ Chat/        # ì±„íŒ… ê´€ë ¨
â”‚   â”œâ”€â”€ UI/          # ê³µí†µ UI
â”‚   â””â”€â”€ Layout/      # ë ˆì´ì•„ì›ƒ
â”œâ”€â”€ contexts/        # Context API
â”œâ”€â”€ hooks/           # Custom Hooks
â””â”€â”€ types/           # TypeScript íƒ€ì…
```

#### CLI Interface
- **ìœ„ì¹˜**: `app/cli/`
- **ê¸°ëŠ¥**: í„°ë¯¸ë„ ê¸°ë°˜ ì¸í„°í˜ì´ìŠ¤
- **ëª…ë ¹ì–´**: `/help`, `/mcp`, `/normal`, `/prompt`

### 2. API Gateway Layer

#### FastAPI Server
- **í¬íŠ¸**: 8000
- **ê¸°ìˆ **: FastAPI, Python 3.13+
- **ê¸°ëŠ¥**:
  - RESTful API ì œê³µ
  - WebSocket ì§€ì›
  - ìë™ API ë¬¸ì„œ ìƒì„±
  - CORS ì²˜ë¦¬

```python
# ì£¼ìš” ë¼ìš°í„° êµ¬ì¡°
app/api_server/
â”œâ”€â”€ main.py           # ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
â”œâ”€â”€ routers/          # API ë¼ìš°í„°
â”‚   â”œâ”€â”€ chat.py      # ì±„íŒ… API
â”‚   â”œâ”€â”€ system.py    # ì‹œìŠ¤í…œ API
â”‚   â”œâ”€â”€ rag.py       # RAG API
â”‚   â”œâ”€â”€ feedback.py  # í”¼ë“œë°± API
â”‚   â”œâ”€â”€ mcp.py       # MCP API
â”‚   â””â”€â”€ session.py   # ì„¸ì…˜ API
â”œâ”€â”€ services/        # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”œâ”€â”€ models/          # ë°ì´í„° ëª¨ë¸
â””â”€â”€ websocket_manager.py
```

### 3. Core Services

#### Chat Service
```python
class ChatbotService:
    """ë©”ì¸ ì±—ë´‡ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.llm_client = OllamaClient()
        self.rag_pipeline = RAGPipeline()
        self.reasoning_rag = ReasoningRAGPipeline()  # v3.84+
        self.mcp_manager = MCPManager()
        
    async def process_message(self, message: str, mode: str):
        if mode == "normal":
            return await self._normal_response(message)
        elif mode == "deep_research":
            return await self._deep_research_response(message)
        elif mode == "reasoning":  # v3.84+
            return await self._reasoning_response(message)
```

#### System Service
- **ëª¨ë¸ ê´€ë¦¬**: Ollama ëª¨ë¸ ì‹œì‘/ì¤‘ì§€/ì „í™˜
- **ì„¤ì • ê´€ë¦¬**: í”„ë¡¬í”„íŠ¸, ëª¨ë“œ, ë””ë²„ê·¸ ì„¤ì •
- **ìƒíƒœ ëª¨ë‹ˆí„°ë§**: ì‹œìŠ¤í…œ í—¬ìŠ¤ì²´í¬

#### Session Manager
- **ì„¸ì…˜ ìƒì„±/ì‚­ì œ**: ì‚¬ìš©ì ì„¸ì…˜ ê´€ë¦¬
- **ìƒíƒœ ìœ ì§€**: ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ë³´ê´€
- **ë©”íƒ€ë°ì´í„° ê´€ë¦¬**: ì„¸ì…˜ë³„ ì„¤ì •

### 4. AI & RAG Layer

#### Ollama LLM Integration
```python
# Ollama í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
OLLAMA_CONFIG = {
    "base_url": "http://localhost:11434",
    "models": {
        "main": "gemma3-12b",
        "embedding": "mxbai-embed-large",
        "fast": "gemma3-8b"
    },
    "options": {
        "temperature": 0.7,
        "top_p": 0.9,
        "max_tokens": 4096
    }
}
```

#### RAG Pipeline (v3.77)
```python
class RAGPipeline:
    """2ë‹¨ê³„ RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.vector_store = MilvusVectorStore()
        self.embedder = MxbaiEmbedder()
        self.reranker = BGEReranker()
        
    async def query(self, query: str, use_reranking: bool = True):
        # 1ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰
        candidates = await self.vector_store.search(
            embedding=await self.embedder.embed(query),
            top_k=20
        )
        
        # 2ë‹¨ê³„: Cross Encoder ë¦¬ë­í‚¹
        if use_reranking:
            candidates = await self.reranker.rerank(
                query=query,
                documents=candidates,
                top_k=5
            )
            
        return candidates
```

#### Reasoning RAG (v3.84+)
```python
class ReasoningRAGPipeline:
    """ê³ ê¸‰ ì¶”ë¡  ê¸°ë°˜ RAG"""
    
    async def reasoning_search(self, query: str, mode: str):
        if mode == "self_rag":
            return await self._self_rag_pipeline(query)
        elif mode == "cot_rag":
            return await self._cot_rag_pipeline(query)
        elif mode == "mcts_rag":
            return await self._mcts_rag_pipeline(query)
```

### 5. Data Layer

#### Milvus Vector Database
```yaml
# ì»¬ë ‰ì…˜ êµ¬ì¡°
Collections:
  documents:           # ë©”ì¸ RAG ë¬¸ì„œ
    dimension: 512
    index_type: HNSW
    metric_type: IP
    
  feedback_collection: # ì‚¬ìš©ì í”¼ë“œë°±
    dimension: 512
    fields: [question_embedding, answer_embedding, feedback_type]
    
  reasoning_context:   # ì¶”ë¡  ì»¨í…ìŠ¤íŠ¸ (v3.84+)
    dimension: 512
    fields: [query_embedding, reasoning_type, step_data]
```

#### Vector Store Implementation
```python
class MilvusVectorStore:
    def __init__(self, uri: str = "tcp://localhost:19530"):
        self.client = MilvusClient(uri=uri)
        
    async def add_documents(self, documents: List[Document]):
        """ë¬¸ì„œ ì¶”ê°€"""
        
    async def search(self, embedding: List[float], top_k: int):
        """ë²¡í„° ê²€ìƒ‰"""
        
    async def hybrid_search(self, query: str, filters: Dict):
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰"""
```

### 6. External Services

#### MCP (Model Context Protocol) Integration
```python
# MCP ì„œë²„ êµ¬ì„±
MCP_SERVERS = {
    "drugbank": {
        "command": "python -m mcp_drugbank",
        "args": ["--api-key", "${DRUGBANK_API_KEY}"]
    },
    "pubmed": {
        "command": "python -m mcp_pubmed", 
        "args": ["--max-results", "10"]
    },
    "biomcp": {
        "command": "python -m biomcp_server",
        "args": ["--database-path", "./data/bio.db"]
    }
}
```

#### External API Integration
- **DrugBank**: ì•½ë¬¼ ì •ë³´ ë°ì´í„°ë² ì´ìŠ¤
- **OpenTargets**: ìœ ì „ì-ì§ˆë³‘ ì—°ê´€ì„±
- **ChEMBL**: í™”í•©ë¬¼ ë°ì´í„°ë² ì´ìŠ¤
- **PubMed**: í•™ìˆ  ë…¼ë¬¸ ê²€ìƒ‰

## ğŸ”„ ë°ì´í„° í”Œë¡œìš°

### 1. ì¼ë°˜ ì±„íŒ… í”Œë¡œìš°
```mermaid
sequenceDiagram
    participant User
    participant WebUI
    participant FastAPI
    participant ChatService
    participant Ollama
    
    User->>WebUI: ë©”ì‹œì§€ ì…ë ¥
    WebUI->>FastAPI: POST /api/chat/message
    FastAPI->>ChatService: process_message()
    ChatService->>Ollama: generate_response()
    Ollama-->>ChatService: LLM ì‘ë‹µ
    ChatService-->>FastAPI: ì‘ë‹µ ë°˜í™˜
    FastAPI-->>WebUI: JSON ì‘ë‹µ
    WebUI-->>User: ì‘ë‹µ í‘œì‹œ
```

### 2. RAG ì¿¼ë¦¬ í”Œë¡œìš°
```mermaid
sequenceDiagram
    participant User
    participant API
    participant RAGPipeline
    participant Milvus
    participant Reranker
    participant Ollama
    
    User->>API: POST /api/rag/query
    API->>RAGPipeline: query()
    RAGPipeline->>Milvus: vector_search(embedding)
    Milvus-->>RAGPipeline: í›„ë³´ ë¬¸ì„œ (k=20)
    RAGPipeline->>Reranker: rerank(query, docs)
    Reranker-->>RAGPipeline: ì •ì œëœ ë¬¸ì„œ (k=5)
    RAGPipeline->>Ollama: generate_answer(context)
    Ollama-->>RAGPipeline: ìµœì¢… ë‹µë³€
    RAGPipeline-->>API: ê²°ê³¼ ë°˜í™˜
    API-->>User: ì‘ë‹µ
```

### 3. Deep Research í”Œë¡œìš°
```mermaid
sequenceDiagram
    participant User
    participant API
    participant MCPManager
    participant DrugBank
    participant PubMed
    participant RAGPipeline
    
    User->>API: Deep Research ì§ˆë¬¸
    API->>MCPManager: start_deep_research()
    MCPManager->>DrugBank: ì•½ë¬¼ ì •ë³´ ê²€ìƒ‰
    MCPManager->>PubMed: ë…¼ë¬¸ ê²€ìƒ‰
    DrugBank-->>MCPManager: ì•½ë¬¼ ë°ì´í„°
    PubMed-->>MCPManager: ë…¼ë¬¸ ë°ì´í„°
    MCPManager->>RAGPipeline: í†µí•© ë¶„ì„
    RAGPipeline-->>MCPManager: ì¢…í•© ê²°ê³¼
    MCPManager-->>API: Sequential Thinking ë³´ê³ ì„œ
    API-->>User: ìµœì¢… ì—°êµ¬ ë³´ê³ ì„œ
```

### 4. Reasoning RAG í”Œë¡œìš° (v3.84+)
```mermaid
sequenceDiagram
    participant User
    participant API
    participant ReasoningRAG
    participant Agent
    participant Search
    participant Synthesis
    
    User->>API: ë³µì¡í•œ ì—°êµ¬ ì§ˆë¬¸
    API->>ReasoningRAG: reasoning_search()
    ReasoningRAG->>Agent: ì§ˆë¬¸ ë¶„ì„ ë° ê³„íš
    Agent->>Search: ë°˜ë³µì  ê²€ìƒ‰ ì‹¤í–‰
    Search->>Search: ì¿¼ë¦¬ ê°œì„  ë° ê²€ìƒ‰
    Search-->>Agent: ê²€ìƒ‰ ê²°ê³¼ í‰ê°€
    Agent->>Synthesis: ì¦ê±° í†µí•© ë° ì¶”ë¡ 
    Synthesis-->>ReasoningRAG: ìµœì¢… ë‹µë³€
    ReasoningRAG-->>API: ì¶”ë¡  ê³¼ì • + ë‹µë³€
    API-->>User: ë‹¨ê³„ë³„ ì¶”ë¡  ê²°ê³¼
```

## ğŸ”’ ë³´ì•ˆ ë° ì¸ì¦

### CORS ì„¤ì •
```python
CORS_CONFIG = {
    "allow_origins": [
        "http://localhost:3003",  # WebUI
        "http://localhost:3000",  # ê°œë°œ ì„œë²„
        "http://127.0.0.1:*"     # ë¡œì»¬ ì ‘ê·¼
    ],
    "allow_credentials": True,
    "allow_methods": ["*"],
    "allow_headers": ["*"]
}
```

### API í‚¤ ê´€ë¦¬
```python
# í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ì„¤ì •
API_KEYS = {
    "drugbank": os.getenv("DRUGBANK_API_KEY"),
    "pubmed": os.getenv("PUBMED_API_KEY"),
    "openai": os.getenv("OPENAI_API_KEY")  # í•„ìš”ì‹œ
}
```

### ì—ëŸ¬ ì²˜ë¦¬
```python
class APIErrorHandler:
    """í†µí•© ì—ëŸ¬ ì²˜ë¦¬"""
    
    @staticmethod
    def handle_ollama_error(error):
        """Ollama ì—°ê²° ì˜¤ë¥˜ ì²˜ë¦¬"""
        
    @staticmethod 
    def handle_milvus_error(error):
        """Milvus ì—°ê²° ì˜¤ë¥˜ ì²˜ë¦¬"""
        
    @staticmethod
    def handle_mcp_error(error):
        """MCP ì„œë²„ ì˜¤ë¥˜ ì²˜ë¦¬"""
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### ë¡œê¹… ì‹œìŠ¤í…œ
```python
LOGGING_CONFIG = {
    "version": 1,
    "handlers": {
        "file": {
            "class": "logging.FileHandler",
            "filename": "/tmp/gaia-bt-api.log",
            "level": "INFO"
        },
        "console": {
            "class": "logging.StreamHandler",
            "level": "DEBUG"
        }
    },
    "loggers": {
        "gaia_bt": {
            "handlers": ["file", "console"],
            "level": "INFO"
        }
    }
}
```

### ì„±ëŠ¥ ë©”íŠ¸ë¦­
```python
class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
    
    def track_request(self, endpoint: str, duration: float):
        """API ìš”ì²­ ì„±ëŠ¥ ì¶”ì """
        
    def track_rag_query(self, query_time: float, results: int):
        """RAG ì¿¼ë¦¬ ì„±ëŠ¥ ì¶”ì """
        
    def track_reasoning(self, steps: int, total_time: float):
        """ì¶”ë¡  ì„±ëŠ¥ ì¶”ì """
```

### í—¬ìŠ¤ì²´í¬ ì‹œìŠ¤í…œ
```python
@app.get("/health")
async def health_check():
    """ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
    return {
        "status": "healthy",
        "services": {
            "ollama": await check_ollama_health(),
            "milvus": await check_milvus_health(),
            "mcp": await check_mcp_health()
        },
        "timestamp": datetime.utcnow().isoformat()
    }
```

## ğŸš€ ë°°í¬ ë° í™•ì¥ì„±

### Docker ì»¨í…Œì´ë„ˆí™”
```yaml
# docker-compose.yml êµ¬ì¡°
services:
  gaia-bt-api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - MILVUS_URI=tcp://milvus:19530
      
  gaia-bt-web:
    build: ./gaia_chat
    ports:
      - "3003:3000"
      
  milvus:
    image: milvusdb/milvus:v2.4.5
    ports:
      - "19530:19530"
      - "9091:9091"
      
  attu:
    image: zilliz/attu:v2.4.8
    ports:
      - "3000:3000"
```

### í™˜ê²½ë³„ ì„¤ì •
```python
# í™˜ê²½ë³„ êµ¬ì„±
class Settings(BaseSettings):
    # ê°œë°œ í™˜ê²½
    development: bool = True
    debug: bool = False
    
    # í”„ë¡œë•ì…˜ í™˜ê²½
    production_mode: bool = False
    enable_https: bool = False
    
    # ìŠ¤ì¼€ì¼ë§ ì„¤ì •
    worker_count: int = 4
    max_connections: int = 1000
    
    class Config:
        env_file = ".env"
```

### ë¡œë“œ ë°¸ëŸ°ì‹±
```python
# ë‹¤ì¤‘ ì¸ìŠ¤í„´ìŠ¤ ì§€ì›
class LoadBalancer:
    """API ì„œë²„ ë¡œë“œ ë°¸ëŸ°ì‹±"""
    
    def __init__(self, servers: List[str]):
        self.servers = servers
        self.current = 0
        
    def get_next_server(self) -> str:
        """ë¼ìš´ë“œ ë¡œë¹ˆ ì„œë²„ ì„ íƒ"""
        server = self.servers[self.current]
        self.current = (self.current + 1) % len(self.servers)
        return server
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### ìºì‹± ì „ëµ
```python
class CacheManager:
    """ë‹¤ì¸µ ìºì‹± ì‹œìŠ¤í…œ"""
    
    # ë©”ëª¨ë¦¬ ìºì‹œ (Redis)
    redis_cache = Redis(host="localhost", port=6379)
    
    # ì„ë² ë”© ìºì‹œ
    embedding_cache = {}
    
    # ê²€ìƒ‰ ê²°ê³¼ ìºì‹œ
    search_cache = TTLCache(maxsize=1000, ttl=3600)
```

### ë¹„ë™ê¸° ì²˜ë¦¬
```python
# ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
async def parallel_search(queries: List[str]):
    """ë³‘ë ¬ ê²€ìƒ‰ ì²˜ë¦¬"""
    tasks = [
        asyncio.create_task(search_single(query))
        for query in queries
    ]
    results = await asyncio.gather(*tasks)
    return results
```

### ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”
```python
# Milvus ì¸ë±ìŠ¤ ì„¤ì •
INDEX_PARAMS = {
    "index_type": "HNSW",
    "metric_type": "IP",
    "params": {
        "M": 16,
        "efConstruction": 200,
        "ef": 100
    }
}
```

## ğŸ”® í–¥í›„ í™•ì¥ ê³„íš

### v3.84-v3.90 ë¡œë“œë§µ
1. **v3.84**: Reasoning RAG ê¸°ë³¸ ì¸í”„ë¼
2. **v3.85**: CoT-RAG ë° ë‹¤ë‹¨ê³„ ì¶”ë¡ 
3. **v3.86**: MCTS-RAG ë° íƒìƒ‰ ìµœì í™”
4. **v3.87**: í”¼ë“œë°± í†µí•© ë° ìë™ í•™ìŠµ
5. **v3.88**: WebUI í†µí•© ë° ì‹œê°í™”
6. **v3.89**: ë„ë©”ì¸ íŠ¹í™” ë° í™•ì¥
7. **v3.90**: ì™„ì „ ìë™í™” ë° ìµœì í™”

### ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ë¶„ë¦¬
```mermaid
graph TB
    subgraph "Core Services"
        CHAT_SVC[Chat Service]
        RAG_SVC[RAG Service]
        REASONING_SVC[Reasoning Service]
        FEEDBACK_SVC[Feedback Service]
    end
    
    subgraph "Data Services"
        VECTOR_SVC[Vector Service]
        EMBEDDING_SVC[Embedding Service]
        CACHE_SVC[Cache Service]
    end
    
    subgraph "External Services"
        MCP_SVC[MCP Service]
        LLM_SVC[LLM Service]
    end
    
    API_GATEWAY[API Gateway] --> CHAT_SVC
    API_GATEWAY --> RAG_SVC
    API_GATEWAY --> REASONING_SVC
    
    CHAT_SVC --> LLM_SVC
    RAG_SVC --> VECTOR_SVC
    REASONING_SVC --> EMBEDDING_SVC
```

---

**GAIA-BT System Architecture v3.84** - í™•ì¥ ê°€ëŠ¥í•˜ê³  ëª¨ë“ˆí™”ëœ ì‹ ì•½ê°œë°œ AI ì‹œìŠ¤í…œ ğŸ—ï¸ğŸ§¬

ì´ ì•„í‚¤í…ì²˜ ë¬¸ì„œëŠ” GAIA-BT ì‹œìŠ¤í…œì˜ ì „ì²´ êµ¬ì¡°ì™€ ê° ì»´í¬ë„ŒíŠ¸ ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ í¬ê´„ì ìœ¼ë¡œ ì„¤ëª…í•˜ë©°, ì‹œìŠ¤í…œì˜ ì´í•´ì™€ ìœ ì§€ë³´ìˆ˜, í™•ì¥ì„ ìœ„í•œ ì™„ì „í•œ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.