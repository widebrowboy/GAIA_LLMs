"""
System Router - ì‹œìŠ¤í…œ ê´€ë ¨ API ì—”ë“œí¬ì¸íŠ¸
"""

from fastapi import APIRouter, HTTPException, Depends
from typing import Dict, Any, List
from pydantic import BaseModel

from app.api_server.dependencies import get_chatbot_service
from app.api_server.services.chatbot_service import ChatbotService
from app.utils.config import OLLAMA_MODEL, DEBUG_MODE
from app.utils.prompt_manager import get_prompt_manager

router = APIRouter()

class SystemInfo(BaseModel):
    """ì‹œìŠ¤í…œ ì •ë³´ ëª¨ë¸"""
    version: str = "2.0.0"
    model: str
    mode: str
    mcp_enabled: bool
    debug: bool
    available_models: List[str]
    available_prompts: List[str]

class ModelChangeRequest(BaseModel):
    """ëª¨ë¸ ë³€ê²½ ìš”ì²­"""
    model_name: str
    session_id: str = "default"

class PromptChangeRequest(BaseModel):
    """í”„ë¡¬í”„íŠ¸ ë³€ê²½ ìš”ì²­"""
    prompt_type: str
    session_id: str = "default"

@router.get("/info", response_model=SystemInfo)
async def get_system_info(
    service: ChatbotService = Depends(get_chatbot_service)
) -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ"""
    prompt_manager = get_prompt_manager()
    
    return {
        "version": "2.0.0",
        "model": service.current_model,
        "mode": service.current_mode,
        "mcp_enabled": service.mcp_enabled,
        "debug": service.debug_mode,
        "available_models": ["gemma3:latest", "llama3.2:latest", "mistral:latest"],
        "available_prompts": list(prompt_manager.templates.keys())
    }

@router.post("/model")
async def change_model(
    request: ModelChangeRequest,
    service: ChatbotService = Depends(get_chatbot_service)
) -> Dict[str, Any]:
    """AI ëª¨ë¸ ë³€ê²½"""
    chatbot = service.get_session(request.session_id)
    if not chatbot:
        raise HTTPException(404, f"ì„¸ì…˜ {request.session_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    try:
        result = await chatbot.change_model(request.model_name)
        return {
            "success": True,
            "model": chatbot.client.model_name,
            "message": result
        }
    except Exception as e:
        raise HTTPException(400, str(e))

@router.post("/prompt")
async def change_prompt(
    request: PromptChangeRequest,
    service: ChatbotService = Depends(get_chatbot_service)
) -> Dict[str, Any]:
    """í”„ë¡¬í”„íŠ¸ íƒ€ì… ë³€ê²½"""
    chatbot = service.get_session(request.session_id)
    if not chatbot:
        raise HTTPException(404, f"ì„¸ì…˜ {request.session_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    try:
        result = await chatbot.change_prompt(request.prompt_type)
        return {
            "success": True,
            "prompt_type": chatbot.current_prompt_type,
            "message": result
        }
    except Exception as e:
        raise HTTPException(400, str(e))

@router.post("/debug")
async def toggle_debug(
    session_id: str = "default",
    service: ChatbotService = Depends(get_chatbot_service)
) -> Dict[str, Any]:
    """ë””ë²„ê·¸ ëª¨ë“œ í† ê¸€"""
    result = await service.process_command("/debug", session_id)
    return result

@router.post("/mode/{mode}")
async def change_mode(
    mode: str,
    session_id: str = "default",
    service: ChatbotService = Depends(get_chatbot_service)
) -> Dict[str, Any]:
    """ëª¨ë“œ ë³€ê²½ (normal/deep_research)"""
    if mode not in ["normal", "deep_research"]:
        raise HTTPException(400, "ìœ íš¨í•˜ì§€ ì•Šì€ ëª¨ë“œì…ë‹ˆë‹¤")
    
    if mode == "normal":
        result = await service.process_command("/normal", session_id)
    else:
        result = await service.process_command("/mcp start", session_id)
    
    return result

@router.get("/startup-banner")
async def get_startup_banner(
    service: ChatbotService = Depends(get_chatbot_service)
) -> Dict[str, Any]:
    """ì‹œì‘ ë°°ë„ˆ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    prompt_manager = get_prompt_manager()
    default_prompt = prompt_manager.get_prompt_template("default")
    prompt_desc = default_prompt.description if default_prompt else "ì‹ ì•½ê°œë°œ ì „ë¬¸ AI"
    
    return {
        "version": "2.0.0",
        "model": service.current_model,
        "prompt_type": "default",
        "prompt_description": prompt_desc,
        "features": [
            "ğŸ’Š ì‹ ì•½ê°œë°œ ì „ë¬¸ AI - ë¶„ìë¶€í„° ì„ìƒê¹Œì§€ ì „ ê³¼ì • ì§€ì›",
            "ğŸ§¬ ê³¼í•™ì  ê·¼ê±° ê¸°ë°˜ ë‹µë³€ - ì°¸ê³ ë¬¸í—Œê³¼ í•¨ê»˜ ì œê³µ",
            "ğŸ¯ ì „ë¬¸ í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ - ëª©ì ì— ë§ëŠ” ì „ë¬¸í™”ëœ ì‘ë‹µ"
        ]
    }