"""
GAIA-BT FastAPI Application
ë©”ì¸ API ì„œë²„ - ëª¨ë“  ì±—ë´‡ ê¸°ëŠ¥ì„ RESTful APIë¡œ ì œê³µ
"""

from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect, Request
from fastapi.middleware.cors import CORSMiddleware
from starlette.middleware.base import BaseHTTPMiddleware
from fastapi.responses import JSONResponse
from fastapi.responses import StreamingResponse
from fastapi.responses import JSONResponse
from contextlib import asynccontextmanager
import logging
from typing import Dict, Any
import traceback
import asyncio

from app.api_server.routers import chat, system, mcp, session
from app.api_server.services.chatbot_service import ChatbotService
from app.api_server.websocket_manager import WebSocketManager
from app.utils.config import OLLAMA_MODEL

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
chatbot_service: ChatbotService = None
websocket_manager: WebSocketManager = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬"""
    global chatbot_service, websocket_manager
    
    # ì‹œì‘ ì‹œ ì´ˆê¸°í™”
    logger.info("ğŸš€ GAIA-BT API Server ì‹œì‘ ì¤‘...")
    
    # 1. Ollama ëª¨ë¸ ìƒíƒœ ê²€ì¦ ë° ìë™ ì‹œì‘ (ìµœìš°ì„ )
    validation_result = None
    try:
        from app.utils.startup_validator import validate_ollama_startup
        validation_result = await validate_ollama_startup()
        
        if not validation_result["validation_success"]:
            error_msg = f"âŒ Ollama ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨: {validation_result['error']}"
            logger.error(error_msg)
            logger.error(f"ğŸ“ ì‹¤íŒ¨ ë‹¨ê³„: {validation_result['stage']}")
            
            # ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨ì¸ ê²½ìš°ì—ë§Œ ì„œë²„ ì‹œì‘ ì¤‘ë‹¨
            if validation_result['stage'] in ['service_check', 'no_models_installed']:
                logger.error("ğŸš¨ í¬ë¦¬í‹°ì»¬ ì˜¤ë¥˜ - API ì„œë²„ ì‹œì‘ ì¤‘ë‹¨")
                raise RuntimeError(f"API ì„œë²„ ì‹œì‘ ë¶ˆê°€: {validation_result['error']}")
            else:
                # ëª¨ë¸ ì‹œì‘ ê´€ë ¨ ì˜¤ë¥˜ëŠ” ê²½ê³ ë¡œë§Œ ì²˜ë¦¬í•˜ê³  ì„œë²„ëŠ” ê³„ì† ì‹œì‘
                logger.warning(f"âš ï¸ Ollama ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨í•˜ì§€ë§Œ ì„œë²„ëŠ” ê³„ì† ì‹œì‘: {validation_result['error']}")
                validation_result["validation_success"] = True  # ê°•ì œë¡œ ì„±ê³µìœ¼ë¡œ ë³€ê²½
                validation_result["message"] = f"ì„œë²„ ì‹œì‘ (ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨: {validation_result['error']})"
        else:
            logger.info(f"âœ… Ollama ëª¨ë¸ ê²€ì¦ ì„±ê³µ: {validation_result.get('message', 'ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ')}")
            if validation_result.get("started_model"):
                logger.info(f"ğŸ¯ ìë™ ì‹œì‘ëœ ëª¨ë¸: {validation_result['started_model']}")
                
    except Exception as e:
        error_msg = f"âŒ Ollama ëª¨ë¸ ê²€ì¦ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}"
        logger.error(error_msg)
        
        # í¬ë¦¬í‹°ì»¬ ì„œë¹„ìŠ¤ ì˜¤ë¥˜ì¸ì§€ í™•ì¸
        if "ì—°ê²°" in str(e) or "service" in str(e).lower() or "tags" in str(e).lower():
            logger.error("ğŸš¨ Ollama ì„œë¹„ìŠ¤ ì—°ê²° ë¶ˆê°€ - ì„œë²„ ì‹œì‘ ì¤‘ë‹¨")
            raise RuntimeError(f"API ì„œë²„ ì‹œì‘ ë¶ˆê°€: {error_msg}")
        else:
            # ê¸°íƒ€ ì˜¤ë¥˜ëŠ” ê²½ê³ ë¡œ ì²˜ë¦¬
            logger.warning(f"âš ï¸ Ollama ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒí•˜ì§€ë§Œ ì„œë²„ëŠ” ê³„ì† ì‹œì‘: {str(e)}")
            validation_result = {
                "validation_success": True,
                "stage": "fallback",
                "message": f"ì„œë²„ ì‹œì‘ (ê²€ì¦ ì˜¤ë¥˜: {str(e)})",
                "running_models": [],
                "started_model": None
            }
    
    # 2. ChatbotService ì´ˆê¸°í™”
    try:
        chatbot_service = ChatbotService()
        await chatbot_service.initialize()
        logger.info("âœ… ChatbotService ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ ChatbotService ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        raise RuntimeError(f"ChatbotService ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
    
    # 3. WebSocket ë§¤ë‹ˆì € ì´ˆê¸°í™”
    try:
        websocket_manager = WebSocketManager()
        logger.info("âœ… WebSocketManager ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ WebSocketManager ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        raise RuntimeError(f"WebSocketManager ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
    
    # ì˜ì¡´ì„± ì£¼ì…ì„ ìœ„í•œ ìƒíƒœ ì €ì¥
    app.state.chatbot_service = chatbot_service
    app.state.websocket_manager = websocket_manager
    app.state.ollama_validation = validation_result  # ê²€ì¦ ê²°ê³¼ë„ ì €ì¥
    
    logger.info("âœ… GAIA-BT API Server ì¤€ë¹„ ì™„ë£Œ")
    logger.info(f"ğŸ¯ í™œì„± ëª¨ë¸: {validation_result.get('running_models', [])}")
    # ì‹œìŠ¤í…œ ì •ìƒ ì‘ë™ í™•ì¸
    
    yield
    
    # ì¢…ë£Œ ì‹œ ì •ë¦¬
    logger.info("ğŸ›‘ GAIA-BT API Server ì¢…ë£Œ ì¤‘...")
    if chatbot_service:
        await chatbot_service.shutdown()
    logger.info("ğŸ‘‹ GAIA-BT API Server ì¢…ë£Œ ì™„ë£Œ")

# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
app = FastAPI(
    title="GAIA-BT Drug Development Research API",
    description="""
## ğŸ§¬ GAIA-BT API v3.60 - ì‹ ì•½ê°œë°œ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸

GAIA-BTëŠ” **Ollama LLM**ê³¼ **Database (MCP)** í†µí•©ì„ í™œìš©í•œ ìµœì²¨ë‹¨ ì‹ ì•½ê°œë°œ ì „ë¬¸ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

### ğŸ“‹ ì£¼ìš” ê¸°ëŠ¥

#### 1. **ë”¥ë¦¬ì„œì¹˜ ëª¨ë“œ** ğŸ”¬
- **Database í†µí•© ê²€ìƒ‰**: DrugBank, OpenTargets, ChEMBL, BioMCP, Web Search
- **Sequential Thinking**: 4ë‹¨ê³„ ì²´ê³„ì  ì‚¬ê³  í”„ë¡œì„¸ìŠ¤
- **ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘**: ìµœì‹  3-5ë…„ ë¦¬ë·° ë…¼ë¬¸ ì¤‘ì  ê²€ìƒ‰
- **APA ìŠ¤íƒ€ì¼ ì¸ìš©**: ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ì— ëŒ€í•œ í‘œì¤€ í•™ìˆ  ì¸ìš©

#### 2. **ëŒ€í™”í˜• AI ì±—ë´‡** ğŸ’¬
- **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ**: SSE(Server-Sent Events) ê¸°ë°˜
- **ë‹¤ì¤‘ ì„¸ì…˜ ì§€ì›**: ì‚¬ìš©ìë³„ ë…ë¦½ì ì¸ ëŒ€í™” ê´€ë¦¬
- **ë§ˆí¬ë‹¤ìš´ í¬ë§·íŒ…**: ì „ë¬¸ì ì¸ ì—°êµ¬ ë³´ê³ ì„œ í˜•ì‹ ì§€ì›

#### 3. **ëª¨ë¸ ê´€ë¦¬ ì‹œìŠ¤í…œ** ğŸ¯
- **ìë™ ëª¨ë¸ ê²€ì¦**: ì„œë²„ ì‹œì‘ ì‹œ Ollama ëª¨ë¸ ìƒíƒœ í™•ì¸
- **ë™ì  ëª¨ë¸ ì „í™˜**: ì‹¤ì‹œê°„ ëª¨ë¸ ë³€ê²½ ê°€ëŠ¥
- **ëª¨ë¸ ìƒíƒœ ëª¨ë‹ˆí„°ë§**: ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ ëª©ë¡ ë° ìƒíƒœ ì¶”ì 

#### 4. **Database í†µí•© (MCP)** ğŸŒ
- **BioMCP**: PubMed, ClinicalTrials, MyVariant í†µí•©
- **DrugBank**: ì•½ë¬¼ ì •ë³´ ë° ìƒí˜¸ì‘ìš© ë°ì´í„°
- **OpenTargets**: íƒ€ê²Ÿ ê²€ì¦ ë° ì§ˆí™˜ ì—°ê´€ì„±
- **ChEMBL**: í™”í•©ë¬¼ ë°”ì´ì˜¤í™œì„± ë°ì´í„°
- **Web Search**: í•™ìˆ  ë¦¬ë·° ë…¼ë¬¸ ì¤‘ì‹¬ ê²€ìƒ‰

### ğŸš€ ë¹ ë¥¸ ì‹œì‘

1. **í—¬ìŠ¤ ì²´í¬**: `GET /health`
2. **ì±„íŒ… ì‹œì‘**: `POST /api/chat/message`
3. **ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ…**: `POST /api/chat/stream`
4. **WebSocket ì—°ê²°**: `ws://localhost:8000/ws/{session_id}`

### ğŸ“Œ ì£¼ìš” ì—”ë“œí¬ì¸íŠ¸

- **Chat API**: ëŒ€í™”í˜• AI ê¸°ëŠ¥ (`/api/chat/*`)
- **System API**: ì‹œìŠ¤í…œ ìƒíƒœ ë° ëª¨ë¸ ê´€ë¦¬ (`/api/system/*`)
- **Database API**: Database ê²€ìƒ‰ ê¸°ëŠ¥ (`/api/mcp/*`)
- **Session API**: ì„¸ì…˜ ê´€ë¦¬ (`/api/session/*`)

### ğŸ’¡ ì‚¬ìš© ì˜ˆì‹œ

#### ì¼ë°˜ ëŒ€í™”
```bash
curl -X POST "http://localhost:8000/api/chat/message" \
  -H "Content-Type: application/json" \
  -d '{"message": "ì•„ìŠ¤í”¼ë¦°ì˜ ì‘ìš© ë©”ì»¤ë‹ˆì¦˜ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”", "session_id": "default"}'
```

#### ë”¥ë¦¬ì„œì¹˜ ëª¨ë“œ í™œì„±í™”
```bash
# 1. ë”¥ë¦¬ì„œì¹˜ ëª¨ë“œ ì‹œì‘
curl -X POST "http://localhost:8000/api/chat/command" \
  -H "Content-Type: application/json" \
  -d '{"command": "/mcp start", "session_id": "research"}'

# 2. ë”¥ë¦¬ì„œì¹˜ ì§ˆë¬¸
curl -X POST "http://localhost:8000/api/chat/message" \
  -H "Content-Type: application/json" \
  -d '{"message": "EGFR í‘œì  í•­ì•”ì œì˜ ìµœì‹  ì„ìƒì‹œí—˜ ê²°ê³¼ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”", "session_id": "research"}'
```

#### ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
```javascript
const response = await fetch('http://localhost:8000/api/chat/stream', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    message: "BRCA1 ìœ ì „ì ë³€ì´ì™€ ê´€ë ¨ëœ ìµœì‹  ì¹˜ë£Œë²•ì€?",
    session_id: "stream_demo"
  })
});

const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  const chunk = decoder.decode(value);
  const lines = chunk.split('\\n');
  
  for (const line of lines) {
    if (line.startsWith('data: ')) {
      const data = line.slice(6);
      if (data === '[DONE]') {
        console.log('ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ');
        break;
      }
      console.log('ì²­í¬:', JSON.parse(data));
    }
  }
}
```

### ğŸ“Š ì‘ë‹µ í˜•ì‹

#### ì¼ë°˜ ì‘ë‹µ
```json
{
  "response": "ì•„ìŠ¤í”¼ë¦°ì€ COX-1ê³¼ COX-2 íš¨ì†Œë¥¼ ë¹„ê°€ì—­ì ìœ¼ë¡œ ì–µì œí•˜ì—¬...",
  "mode": "normal",
  "model": "gemma3-12b:latest"
}
```

#### ë”¥ë¦¬ì„œì¹˜ ì‘ë‹µ
```json
{
  "response": "# EGFR í‘œì  í•­ì•”ì œ ìµœì‹  ì„ìƒì‹œí—˜ ë¶„ì„\n\n## ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼\n\n### OpenTargets ë°ì´í„°\n- EGFR (ENSG00000146648) íƒ€ê²Ÿ ê²€ì¦ ì ìˆ˜: 0.95\n...",
  "mode": "deep_research",
  "model": "gemma3-12b:latest",
  "sources": ["OpenTargets", "DrugBank", "ChEMBL", "ClinicalTrials"]
}
```

### ğŸ”’ ì¸ì¦ ë° ë³´ì•ˆ

í˜„ì¬ ë²„ì „ì€ ê°œë°œìš©ìœ¼ë¡œ ì¸ì¦ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ë‹¤ìŒì„ ê¶Œì¥í•©ë‹ˆë‹¤:
- API í‚¤ ê¸°ë°˜ ì¸ì¦
- HTTPS ì‚¬ìš©
- Rate limiting ì ìš©
- CORS ì •ì±… ê°•í™”

### ğŸ”— ê´€ë ¨ ë§í¬

- **API ë¬¸ì„œ**: http://localhost:8000/docs
- **WebUI**: http://localhost:3003
- **GitHub**: https://github.com/your-repo/gaia-bt
""",
    version="3.60.0",
    lifespan=lifespan,
    openapi_tags=[
        {
            "name": "chat",
            "description": "ëŒ€í™”í˜• AI ì±—ë´‡ ê¸°ëŠ¥ - ì¼ë°˜ ëŒ€í™” ë° ë”¥ë¦¬ì„œì¹˜ ëª¨ë“œ ì§€ì›"
        },
        {
            "name": "system",
            "description": "ì‹œìŠ¤í…œ ê´€ë¦¬ - ëª¨ë¸ ìƒíƒœ, ì„¤ì •, í”„ë¡¬í”„íŠ¸ ê´€ë¦¬"
        },
        {
            "name": "mcp",
            "description": "Database ê²€ìƒ‰ ë° í†µí•© - DrugBank, OpenTargets, ChEMBL ë“± ìƒëª…ê³¼í•™ ë°ì´í„°ë² ì´ìŠ¤ ì ‘ê·¼"
        },
        {
            "name": "session",
            "description": "ì„¸ì…˜ ê´€ë¦¬ - ë‹¤ì¤‘ ì‚¬ìš©ì ëŒ€í™” ì„¸ì…˜ ì²˜ë¦¬"
        }
    ],
    servers=[
        {
            "url": "http://localhost:8000",
            "description": "ë¡œì»¬ ê°œë°œ ì„œë²„"
        },
        {
            "url": "https://api.gaia-bt.com",
            "description": "í”„ë¡œë•ì…˜ ì„œë²„ (ì˜ˆì‹œ)"
        }
    ]
)

# UTF-8 ì¸ì½”ë”© ê°•ì œ ì„¤ì •ì„ ìœ„í•œ ë¯¸ë“¤ì›¨ì–´
class UTF8EncodingMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request, call_next):
        response = await call_next(request)
        
        # JSON ì‘ë‹µì— UTF-8 ì¸ì½”ë”© ëª…ì‹œ
        if isinstance(response, JSONResponse):
            response.headers["Content-Type"] = "application/json; charset=utf-8"
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì— UTF-8 ì¸ì½”ë”© ëª…ì‹œ (SSE)
        elif isinstance(response, StreamingResponse) and response.media_type == "text/event-stream":
            response.headers["Content-Type"] = "text/event-stream; charset=utf-8"
        
        return response

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ì˜¤ë¦¬ì§„ í—ˆìš© (ê°œë°œìš©)
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# UTF-8 ì¸ì½”ë”© ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€
app.add_middleware(UTF8EncodingMiddleware)

# ì „ì—­ ì˜ˆì™¸ ì²˜ë¦¬ê¸°
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    """ì „ì—­ ì˜ˆì™¸ ì²˜ë¦¬ - JSON ì‘ë‹µ ë³´ì¥"""
    # ìƒì„¸í•œ ì˜¤ë¥˜ ì •ë³´ ë¡œê¹…
    error_details = {
        "error_type": type(exc).__name__,
        "error_message": str(exc),
        "request_url": str(request.url),
        "request_method": request.method,
        "request_headers": dict(request.headers),
        "traceback": traceback.format_exc()
    }
    
    logger.error(f"ğŸš¨ Internal Server Error occurred:")
    logger.error(f"ğŸ“ URL: {request.method} {request.url}")
    logger.error(f"ğŸ” Error Type: {type(exc).__name__}")
    logger.error(f"ğŸ’¬ Error Message: {str(exc)}")
    logger.error(f"ğŸ“‹ Full Traceback:\n{traceback.format_exc()}")
    
    # PromptManager ê´€ë ¨ ì˜¤ë¥˜ íŠ¹ë³„ ì²˜ë¦¬
    if "PromptManager" in str(exc) or "templates" in str(exc):
        logger.error("ğŸ¯ PromptManager ê´€ë ¨ ì˜¤ë¥˜ ê°ì§€ - templates property ì ‘ê·¼ ë¬¸ì œì¼ ê°€ëŠ¥ì„±")
    
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal Server Error",
            "message": str(exc),
            "type": type(exc).__name__,
            "timestamp": str(asyncio.get_event_loop().time()) if hasattr(asyncio, 'get_event_loop') else None
        }
    )

@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    """HTTP ì˜ˆì™¸ ì²˜ë¦¬ - JSON ì‘ë‹µ ë³´ì¥"""
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": exc.detail,
            "status_code": exc.status_code
        }
    )

# ë¼ìš°í„° ë“±ë¡
app.include_router(chat.router, prefix="/api/chat", tags=["chat"])
app.include_router(system.router, prefix="/api/system", tags=["system"])
app.include_router(mcp.router, prefix="/api/mcp", tags=["mcp"])
app.include_router(session.router, prefix="/api/session", tags=["session"])

@app.get("/", 
    summary="API ë£¨íŠ¸ ì •ë³´",
    description="GAIA-BT API ì„œë²„ì˜ ê¸°ë³¸ ì •ë³´ì™€ ì‚¬ìš© ê°€ëŠ¥í•œ ì—”ë“œí¬ì¸íŠ¸ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.",
    response_description="API ì„œë²„ ì •ë³´ ë° ì—”ë“œí¬ì¸íŠ¸ ëª©ë¡",
    responses={
        200: {
            "description": "ì„±ê³µì ì¸ ì‘ë‹µ",
            "content": {
                "application/json": {
                    "example": {
                        "name": "GAIA-BT API Server",
                        "version": "3.60.0",
                        "description": "ì‹ ì•½ê°œë°œ ì—°êµ¬ AI ì–´ì‹œìŠ¤í„´íŠ¸",
                        "model": "gemma3-12b:latest",
                        "endpoints": {
                            "chat": "/api/chat",
                            "system": "/api/system",
                            "mcp": "/api/mcp",
                            "session": "/api/session",
                            "docs": "/docs",
                            "websocket": "/ws"
                        }
                    }
                }
            }
        }
    }
)
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ - API ì„œë²„ ì •ë³´ ì œê³µ"""
    return {
        "name": "GAIA-BT API Server",
        "version": "3.60.0",
        "description": "ì‹ ì•½ê°œë°œ ì—°êµ¬ AI ì–´ì‹œìŠ¤í„´íŠ¸",
        "model": OLLAMA_MODEL,
        "endpoints": {
            "chat": "/api/chat",
            "system": "/api/system",
            "mcp": "/api/mcp",
            "session": "/api/session",
            "docs": "/docs",
            "websocket": "/ws"
        }
    }

@app.api_route("/health", methods=["GET", "HEAD"],
    summary="ì„œë²„ ìƒíƒœ í™•ì¸",
    description="""
API ì„œë²„ì˜ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤:

- **ì„œë²„ ìƒíƒœ**: ì •ìƒ ì‘ë™ ì—¬ë¶€
- **í˜„ì¬ ëª¨ë¸**: í™œì„±í™”ëœ Ollama ëª¨ë¸
- **ì‘ë™ ëª¨ë“œ**: normal(ì¼ë°˜) ë˜ëŠ” deep_research(ë”¥ë¦¬ì„œì¹˜)
- **MCP ìƒíƒœ**: Database ê²€ìƒ‰ ê¸°ëŠ¥ í™œì„±í™” ì—¬ë¶€
- **ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ ëª©ë¡**: ëª¨ë“  í™œì„± Ollama ëª¨ë¸

ì´ ì—”ë“œí¬ì¸íŠ¸ëŠ” ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì´ë‚˜ ë¡œë“œ ë°¸ëŸ°ì„œì—ì„œ ì£¼ê¸°ì ìœ¼ë¡œ í˜¸ì¶œí•˜ì—¬ ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•˜ëŠ” ìš©ë„ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
""",
    response_description="ì„œë²„ ìƒíƒœ ì •ë³´",
    responses={
        200: {
            "description": "ì„œë²„ ì •ìƒ ì‘ë™",
            "content": {
                "application/json": {
                    "example": {
                        "status": "healthy",
                        "model": "gemma3-12b:latest",
                        "mode": "normal",
                        "mcp_enabled": True,
                        "debug": False,
                        "running_models": ["gemma3-12b:latest", "txgemma-chat:latest"]
                    }
                }
            }
        }
    }
)
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸

    ìš°ì„  ìˆœìœ„
    1. ì‹¤ì œë¡œ *running* ìƒíƒœì¸ Ollama ëª¨ë¸ ëª©ë¡ì„ ì¡°íšŒí•´ í‘œì‹œ
    2. ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ì´ ì—†ìœ¼ë©´ ChatbotService ì˜ current_model ì‚¬ìš©
    """
    service = app.state.chatbot_service

    from app.utils.ollama_manager import list_running_models  # ëŠ¦ì€ import ë¡œ ì˜ì¡´ ìµœì†Œí™”
    running = await list_running_models()

    # ì²« ë²ˆì§¸ ì‹¤í–‰ ëª¨ë¸(ê°€ì¥ ìµœê·¼ì— ë„ìš´ ëª¨ë¸)ì„ ëŒ€í‘œê°’ìœ¼ë¡œ ì‚¬ìš©
    current_model = running[-1] if running else (service.current_model if service else None)

    return {
        "status": "healthy",
        "model": current_model,
        "mode": service.current_mode if service else None,
        "mcp_enabled": service.mcp_enabled if service else False,
        "debug": service.debug_mode if service else False,
        "running_models": running  # UIì—ì„œ ëª©ë¡ìœ¼ë¡œë„ í™œìš© ê°€ëŠ¥í•˜ë„ë¡ ì¶”ê°€
    }

@app.websocket("/ws/{session_id}")
async def websocket_endpoint(websocket: WebSocket, session_id: str):
    """WebSocket ì—”ë“œí¬ì¸íŠ¸ - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì§€ì›"""
    manager = app.state.websocket_manager
    service = app.state.chatbot_service
    
    await manager.connect(websocket, session_id)
    
    try:
        while True:
            # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ 
            data = await websocket.receive_json()
            
            # ë©”ì‹œì§€ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬
            message_type = data.get("type", "chat")
            
            if message_type == "chat":
                # ì±„íŒ… ë©”ì‹œì§€ ì²˜ë¦¬
                user_input = data.get("message", "")
                
                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
                async for chunk in service.generate_streaming_response(user_input, session_id):
                    await manager.send_message(session_id, {
                        "type": "chat_chunk",
                        "content": chunk,
                        "done": False
                    })
                
                # ì™„ë£Œ ì‹ í˜¸
                await manager.send_message(session_id, {
                    "type": "chat_chunk",
                    "content": "",
                    "done": True
                })
                
            elif message_type == "command":
                # ëª…ë ¹ì–´ ì²˜ë¦¬
                command = data.get("command", "")
                result = await service.process_command(command, session_id)
                
                await manager.send_message(session_id, {
                    "type": "command_result",
                    "result": result
                })
                
    except WebSocketDisconnect:
        manager.disconnect(session_id)
        logger.info(f"WebSocket ì—°ê²° í•´ì œ: {session_id}")
    except Exception as e:
        logger.error(f"WebSocket ì˜¤ë¥˜: {e}")
        manager.disconnect(session_id)

async def test_ollama_model_response(model_name: str = "gemma3-12b:latest") -> dict:
    """Ollama ëª¨ë¸ê³¼ ì‹¤ì œ ëŒ€í™” í…ŒìŠ¤íŠ¸ë¥¼ í†µí•œ ì—°ê²° ìƒíƒœ í™•ì¸"""
    try:
        from app.utils.ollama_manager import list_running_models, start_model
        
        # 1. ëª¨ë¸ì´ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
        running_models = await list_running_models()
        if model_name not in running_models:
            logger.info(f"ëª¨ë¸ '{model_name}' ì‹¤í–‰ë˜ì§€ ì•ŠìŒ, ì‹œì‘ ì‹œë„ ì¤‘...")
            await start_model(model_name)
            running_models = await list_running_models()
        
        # 2. ì‹¤ì œ ëª¨ë¸ ì‘ë‹µ í…ŒìŠ¤íŠ¸
        service = app.state.chatbot_service
        if service and service.sessions:
            # ê¸°ë³¸ ì„¸ì…˜ì˜ í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
            default_session = service.sessions.get("default")
            if default_session and hasattr(default_session, 'client'):
                test_message = "Hello"
                
                # ê°„ë‹¨í•œ ì‘ë‹µ í…ŒìŠ¤íŠ¸ (íƒ€ì„ì•„ì›ƒ 10ì´ˆ)
                import asyncio
                try:
                    response = await asyncio.wait_for(
                        default_session.client.generate(test_message),
                        timeout=10.0
                    )
                    
                    if response and len(response.strip()) > 0:
                        return {
                            "model_ready": True,
                            "model_name": model_name,
                            "running_models": running_models,
                            "test_success": True,
                            "response_length": len(response)
                        }
                    else:
                        return {
                            "model_ready": False,
                            "model_name": model_name,
                            "running_models": running_models,
                            "test_success": False,
                            "error": "Empty response from model"
                        }
                        
                except asyncio.TimeoutError:
                    return {
                        "model_ready": False,
                        "model_name": model_name,
                        "running_models": running_models,
                        "test_success": False,
                        "error": "Model response timeout"
                    }
                    
            else:
                return {
                    "model_ready": False,
                    "model_name": model_name,
                    "running_models": running_models,
                    "test_success": False,
                    "error": "Default session client not available"
                }
                
        else:
            return {
                "model_ready": False,
                "model_name": model_name,
                "running_models": running_models,
                "test_success": False,
                "error": "ChatbotService not available"
            }
            
    except Exception as e:
        logger.error(f"Ollama ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        return {
            "model_ready": False,
            "model_name": model_name,
            "running_models": [],
            "test_success": False,
            "error": str(e)
        }

@app.websocket("/ws/status/{session_id}")
async def status_websocket_endpoint(websocket: WebSocket, session_id: str):
    """ì—°ê²° ìƒíƒœ ëª¨ë‹ˆí„°ë§ ì „ìš© WebSocket ì—”ë“œí¬ì¸íŠ¸"""
    await websocket.accept()
    
    connected = True
    try:
        import asyncio
        
        while connected:
            # ì„œë²„ ìƒíƒœ ì •ë³´ ìˆ˜ì§‘
            try:
                service = app.state.chatbot_service
                
                # ì‹¤ì œ ëª¨ë¸ ëŒ€í™” ê°€ëŠ¥ ìƒíƒœ í…ŒìŠ¤íŠ¸
                model_test_result = await test_ollama_model_response()
                
                status_data = {
                    "type": "status_update",
                    "timestamp": int(asyncio.get_event_loop().time()),
                    "server_healthy": True,
                    "model_ready": model_test_result.get("model_ready", False),
                    "ollama_models": model_test_result.get("running_models", []),
                    "current_model": model_test_result.get("model_name"),
                    "mode": service.current_mode if service else "normal",
                    "mcp_enabled": service.mcp_enabled if service else False,
                    "connected_sessions": len(app.state.websocket_manager.active_connections) if app.state.websocket_manager else 0,
                    "test_result": {
                        "success": model_test_result.get("test_success", False),
                        "error": model_test_result.get("error"),
                        "response_length": model_test_result.get("response_length", 0)
                    }
                }
                
                # WebSocket ì—°ê²° ìƒíƒœ í™•ì¸ í›„ ì „ì†¡
                if connected and websocket.client_state.value == 1:  # CONNECTED
                    try:
                        await websocket.send_json(status_data)
                    except Exception as send_error:
                        logger.warning(f"Status WebSocket ì „ì†¡ ì‹¤íŒ¨: {send_error}")
                        connected = False
                        break
                else:
                    connected = False
                    break
                
            except Exception as e:
                # ì„œë²„ ì˜¤ë¥˜ ì‹œ ìƒíƒœ ì •ë³´
                error_data = {
                    "type": "status_update",
                    "timestamp": int(asyncio.get_event_loop().time()),
                    "server_healthy": False,
                    "model_ready": False,
                    "error": str(e),
                    "ollama_models": [],
                    "current_model": None,
                    "test_result": {
                        "success": False,
                        "error": str(e)
                    }
                }
                
                # WebSocket ì—°ê²° ìƒíƒœ í™•ì¸ í›„ ì „ì†¡
                if connected and websocket.client_state.value == 1:  # CONNECTED
                    try:
                        await websocket.send_json(error_data)
                    except Exception as send_error:
                        logger.warning(f"Error WebSocket ì „ì†¡ ì‹¤íŒ¨: {send_error}")
                        connected = False
                        break
                else:
                    connected = False
                    break
            
            # 10ì´ˆë§ˆë‹¤ ìƒíƒœ ì—…ë°ì´íŠ¸ (ëª¨ë¸ í…ŒìŠ¤íŠ¸ í¬í•¨ìœ¼ë¡œ ê°„ê²© ì¦ê°€)
            try:
                await asyncio.sleep(10)
            except asyncio.CancelledError:
                connected = False
                break
            
    except WebSocketDisconnect:
        logger.info(f"Status WebSocket ì—°ê²° í•´ì œ: {session_id}")
        connected = False
    except Exception as e:
        logger.error(f"Status WebSocket ì˜¤ë¥˜: {e}")
        connected = False

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)