#!/usr/bin/env python3
"""
ëª¨ë“ˆí™”ëœ ì—°êµ¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ê° êµ¬ì„±ìš”ì†Œê°€ ë…ë¦½ì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸
"""

import os
import asyncio
import argparse
from typing import List, Dict, Any

# ëª¨ë“ˆí™”ëœ ì»´í¬ë„ŒíŠ¸ ì„í¬íŠ¸
from src.api.ollama_client import OllamaClient
from src.research.answer_generator import AnswerGenerator
from src.feedback.answer_evaluator import AnswerEvaluator
from src.research.research_manager import ResearchManager

async def test_ollama_client():
    """OllamaClient í…ŒìŠ¤íŠ¸"""
    print("\n===== OllamaClient í…ŒìŠ¤íŠ¸ =====")
    client = OllamaClient()
    
    # API ê°€ìš©ì„± í™•ì¸
    status = await client.check_availability()
    print(f"- API ìƒíƒœ: {status['status']}")
    
    if status['status'] == 'available':
        # GPU ìµœì í™” íŒŒë¼ë¯¸í„° ì¶œë ¥
        print(f"- ëª¨ë¸: {client.model}")
        print(f"- GPU ê°€ì†: num_gpu={client.gpu_params['num_gpu']}, num_thread={client.gpu_params['num_thread']}")
        
        # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
        response = await client.generate(
            prompt="í¬ë ˆì•„í‹´ ëª¨ë…¸í•˜ì´ë“œë ˆì´íŠ¸ì˜ íš¨ëŠ¥ì„ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”.",
            system_prompt="ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì „ë¬¸ê°€ë¡œì„œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.",
            temperature=0.7
        )
        print(f"\n- ìƒì„±ëœ í…ìŠ¤íŠ¸ (ì¼ë¶€): {response[:100]}...")
        
        return True
    else:
        print(f"âŒ APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {status.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        return False

async def test_answer_generator(client: OllamaClient):
    """AnswerGenerator í…ŒìŠ¤íŠ¸"""
    print("\n===== AnswerGenerator í…ŒìŠ¤íŠ¸ =====")
    generator = AnswerGenerator(client)
    
    # ë‹µë³€ ìƒì„± í…ŒìŠ¤íŠ¸
    question = "ê·¼ìœ¡ íšŒë³µì„ ìœ„í•œ BCAAì˜ íš¨ëŠ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    print(f"- ì§ˆë¬¸: {question}")
    
    answer = await generator.generate_answer(question)
    print(f"- ìƒì„±ëœ ë‹µë³€ (ì¼ë¶€): {answer[:150]}...")
    
    # ëŒ€ì²´ ë‹µë³€ ìƒì„± í…ŒìŠ¤íŠ¸
    print("- ëŒ€ì²´ ë‹µë³€ ìƒì„± ì¤‘...")
    alt_answers = await generator.generate_alternative_answers(question, count=2)
    print(f"- ìƒì„±ëœ ëŒ€ì²´ ë‹µë³€ ìˆ˜: {len(alt_answers)}")
    
    # ì—°êµ¬ ì§ˆë¬¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    print("- research_question ë©”ì†Œë“œ í…ŒìŠ¤íŠ¸...")
    result = await generator.research_question(question)
    print(f"- ê²°ê³¼ ê¸¸ì´: {len(result)} ì")
    
    return len(answer) > 0 and len(alt_answers) > 0 and len(result) > 0

async def test_answer_evaluator(client: OllamaClient):
    """AnswerEvaluator í…ŒìŠ¤íŠ¸"""
    print("\n===== AnswerEvaluator í…ŒìŠ¤íŠ¸ =====")
    evaluator = AnswerEvaluator(client)
    generator = AnswerGenerator(client)
    
    # í‰ê°€ í…ŒìŠ¤íŠ¸ìš© ì§ˆë¬¸ê³¼ ë‹µë³€
    question = "ê·¼ìœ¡ ë°œë‹¬ì— ê°€ì¥ ì¤‘ìš”í•œ ì•„ë¯¸ë…¸ì‚°ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    print(f"- ì§ˆë¬¸: {question}")
    
    # ë‹µë³€ ìƒì„±
    answer = await generator.generate_answer(question)
    print(f"- ìƒì„±ëœ ë‹µë³€ (ì¼ë¶€): {answer[:100]}...")
    
    # ë‹µë³€ í‰ê°€
    print("- ë‹µë³€ í‰ê°€ ì¤‘...")
    evaluation = await evaluator.evaluate_answer(question, answer)
    print(f"- ì´ì : {evaluation.get('overall_score', 'N/A')}/10")
    print(f"- ì£¼ìš” í”¼ë“œë°±: {evaluation.get('improvement_suggestions', 'N/A')[:150]}...")
    
    # ê°œì„ ëœ ë‹µë³€ ìƒì„±
    print("- ê°œì„ ëœ ë‹µë³€ ìƒì„± ì¤‘...")
    improved = await evaluator.generate_improved_answer(question, answer, evaluation)
    print(f"- ê°œì„ ëœ ë‹µë³€ (ì¼ë¶€): {improved[:100]}...")
    
    # í”¼ë“œë°± ë£¨í”„ í…ŒìŠ¤íŠ¸ (ê°„ì†Œí™”ëœ ì„¤ì •)
    print("- í”¼ë“œë°± ë£¨í”„ í…ŒìŠ¤íŠ¸ (ê¹Šì´=1, ë„ˆë¹„=1)...")
    feedback_result = await evaluator.feedback_loop(question, answer, depth=1, width=1)
    print(f"- ìµœì¢… ì ìˆ˜: {feedback_result['best_score']}/10")
    
    return "best_score" in feedback_result and "final_answer" in feedback_result

async def test_research_manager(client: OllamaClient):
    """ResearchManager í…ŒìŠ¤íŠ¸"""
    print("\n===== ResearchManager í…ŒìŠ¤íŠ¸ =====")
    manager = ResearchManager(
        ollama_client=client,
        feedback_depth=1,  # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë‚®ì€ ê°’ ì‚¬ìš©
        feedback_width=1,
        concurrent_research=2,
        output_dir="./test_outputs"
    )
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
    questions = [
        "í¬ë ˆì•„í‹´ì˜ ê·¼ìœ¡ ë°œë‹¬ íš¨ê³¼ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
        "ìš´ë™ í›„ ë‹¨ë°±ì§ˆ ì„­ì·¨ ì‹œê°„ì´ ì¤‘ìš”í•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
    ]
    print(f"- í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: {len(questions)}ê°œ")
    
    # ë‹¨ì¼ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
    print(f"\n- ë‹¨ì¼ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸: '{questions[0][:30]}...'")
    single_result = await manager.research_question(questions[0])
    print(f"  - ìƒíƒœ: {single_result.get('status', 'N/A')}")
    print(f"  - ì ìˆ˜: {single_result.get('score', 'N/A')}")
    
    # ì§ˆë¬¸ ëª©ë¡ì— ëŒ€í•œ ì—°êµ¬ í…ŒìŠ¤íŠ¸ (ë‹¨ìˆœí™”)
    print("\n- ì§ˆë¬¸ ëª©ë¡ ì‹¬ì¸µ ì—°êµ¬ í…ŒìŠ¤íŠ¸...")
    print("  (í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ê°„ì†Œí™”ëœ ì„¤ì • ì‚¬ìš©)")
    
    results = await manager.conduct_research(questions[:1])  # ì²« ë²ˆì§¸ ì§ˆë¬¸ë§Œ ì‚¬ìš©
    print(f"  - ì™„ë£Œëœ ì§ˆë¬¸: {results.get('completed_questions', 'N/A')}")
    print(f"  - ì €ì¥ ìœ„ì¹˜: {results.get('output_directory', 'N/A')}")
    
    return single_result.get('status') == 'completed' and 'results' in results

async def main():
    """í…ŒìŠ¤íŠ¸ ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ëª¨ë“ˆí™”ëœ ì—°êµ¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸')
    parser.add_argument('--test', '-t', choices=['all', 'client', 'generator', 'evaluator', 'manager'], 
                      default='all', help='ì‹¤í–‰í•  í…ŒìŠ¤íŠ¸ (ê¸°ë³¸ê°’: all)')
    args = parser.parse_args()
    
    test_type = args.test
    print(f"===== ëª¨ë“ˆí™”ëœ ì—°êµ¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸: {test_type} =====")
    
    # ê¸°ë³¸ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = OllamaClient()
    
    # ì„ íƒëœ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    results = {}
    
    if test_type in ['all', 'client']:
        results['client'] = await test_ollama_client()
        if not results['client']:
            print("âŒ OllamaClient í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - ë‹¤ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
    
    if test_type in ['all', 'generator'] and (test_type != 'all' or results.get('client', True)):
        results['generator'] = await test_answer_generator(client)
        
    if test_type in ['all', 'evaluator'] and (test_type != 'all' or results.get('client', True)):
        results['evaluator'] = await test_answer_evaluator(client)
        
    if test_type in ['all', 'manager'] and (test_type != 'all' or results.get('client', True)):
        results['manager'] = await test_research_manager(client)
        
    # ê²°ê³¼ ìš”ì•½
    print("\n===== í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ =====")
    for test_name, success in results.items():
        status = "âœ… ì„±ê³µ" if success else "âŒ ì‹¤íŒ¨"
        print(f"- {test_name}: {status}")
    
    if all(results.values()):
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("\nâš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    asyncio.run(main())
