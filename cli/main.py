#!/usr/bin/env python3
"""
ê·¼ìœ¡ ê´€ë ¨ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì—°êµ¬ ì‹œìŠ¤í…œ - CLI ì¸í„°í˜ì´ìŠ¤
ëª…ë ¹ì¤„ì—ì„œ ì‹œìŠ¤í…œì˜ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì— ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ì¸í„°í˜ì´ìŠ¤ ì œê³µ
"""

import os
import sys
import asyncio
import argparse
from datetime import datetime
from typing import List, Dict, Any, Optional
import json

# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ ëª¨ë“ˆ ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ëª¨ë“ˆ ì„í¬íŠ¸
from src.api.ollama_client import OllamaClient
from src.research.research_manager import ResearchManager
from src.research.answer_generator import AnswerGenerator
from src.feedback.answer_evaluator import AnswerEvaluator
from src.storage.file_storage import FileStorage

# ë²„ì „ ì •ë³´
VERSION = "1.0.0"


async def handle_single_question(args):
    """
    ë‹¨ì¼ ì§ˆë¬¸ì— ëŒ€í•œ ì—°êµ¬ ìˆ˜í–‰
    """
    print(f"ğŸ“š ì§ˆë¬¸ ì—°êµ¬ ì‹œì‘: '{args.question}'")
    
    # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = OllamaClient(
        model=args.model,
        temperature=args.temperature
    )
    
    # API ê°€ìš©ì„± í™•ì¸
    status = await client.check_availability()
    if status["status"] != "available":
        print(f"âŒ Ollama APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {status.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        return 1
    
    print(f"ğŸš€ {status.get('current_model', client.model)} ëª¨ë¸ ì‚¬ìš© ì¤‘")
    
    # ì—°êµ¬ ê´€ë¦¬ì ì´ˆê¸°í™”
    manager = ResearchManager(
        ollama_client=client,
        feedback_depth=args.depth,
        feedback_width=args.width,
        concurrent_research=args.concurrent,
        output_dir=args.output_dir
    )
    
    # ì—°êµ¬ ìˆ˜í–‰
    start_time = datetime.now()
    result = await manager.research_question(args.question)
    elapsed = (datetime.now() - start_time).total_seconds()
    
    # ê²°ê³¼ ì¶œë ¥
    if "error" in result:
        print(f"âŒ ì—°êµ¬ ì‹¤íŒ¨: {result['error']}")
        return 1
        
    print(f"\nâœ… ì—°êµ¬ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ)")
    print(f"ğŸ“Š í’ˆì§ˆ ì ìˆ˜: {result.get('score', 'N/A')}/10")
    print(f"ğŸ”„ í”¼ë“œë°± ë£¨í”„: {result.get('feedback_loops', 'N/A')}íšŒ")
    print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {manager.file_storage.get_session_directory(manager.session_id)}")
    
    # ê²°ê³¼ ìš”ì•½ í‘œì‹œ
    if args.show_summary:
        answer = result.get("answer", "")
        print("\n" + "=" * 50)
        print("ğŸ“ ì—°êµ¬ ê²°ê³¼ ìš”ì•½ (ì²˜ìŒ 500ì)")
        print("=" * 50)
        print(answer[:500] + "...\n")
        
    return 0


async def handle_questions_file(args):
    """
    íŒŒì¼ì—ì„œ ì§ˆë¬¸ ëª©ë¡ì„ ì½ì–´ ì—°êµ¬ ìˆ˜í–‰
    """
    if not os.path.exists(args.file):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.file}")
        return 1
    
    try:
        with open(args.file, 'r', encoding='utf-8') as f:
            content = f.read().strip()
        
        # íŒŒì¼ í˜•ì‹ í™•ì¸ ë° ì§ˆë¬¸ ì¶”ì¶œ
        if args.file.endswith('.json'):
            try:
                data = json.loads(content)
                if isinstance(data, list):
                    questions = data
                elif isinstance(data, dict) and "questions" in data:
                    questions = data["questions"]
                else:
                    print("âŒ JSON íŒŒì¼ í˜•ì‹ ì˜¤ë¥˜: 'questions' ë°°ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    return 1
            except json.JSONDecodeError:
                print("âŒ ìœ íš¨í•˜ì§€ ì•Šì€ JSON íŒŒì¼ì…ë‹ˆë‹¤")
                return 1
        else:
            # ì¼ë°˜ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì²˜ë¦¬ (ê° í–‰ì„ ì§ˆë¬¸ìœ¼ë¡œ ê°„ì£¼)
            questions = [line.strip() for line in content.split('\n') if line.strip()]
        
        # ë¹ˆ ì§ˆë¬¸ í•„í„°ë§
        questions = [q for q in questions if q]
        
        if not questions:
            print("âŒ íŒŒì¼ì— ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤")
            return 1
            
        print(f"ğŸ“‹ {len(questions)}ê°œ ì§ˆë¬¸ ë¡œë“œ ì™„ë£Œ")
        
        # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        client = OllamaClient(
            model=args.model,
            temperature=args.temperature
        )
        
        # ResearchManager ì´ˆê¸°í™”
        manager = ResearchManager(
            ollama_client=client,
            feedback_depth=args.depth,
            feedback_width=args.width,
            concurrent_research=args.concurrent,
            output_dir=args.output_dir
        )
        
        # ì—°êµ¬ ìˆ˜í–‰
        print(f"\nğŸ” ì‹¬ì¸µ ì—°êµ¬ ì‹œì‘ (ë™ì‹œ ì²˜ë¦¬: {args.concurrent}ê°œ, í”¼ë“œë°± ê¹Šì´: {args.depth}, ë„ˆë¹„: {args.width})")
        start_time = datetime.now()
        results = await manager.conduct_research(questions)
        elapsed = (datetime.now() - start_time).total_seconds()
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nâœ… ì—°êµ¬ ì™„ë£Œ (ì´ ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ)")
        print(f"ğŸ“Š ì™„ë£Œëœ ì§ˆë¬¸: {results.get('completed_questions', 0)}/{len(questions)}")
        print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {results.get('output_directory', 'N/A')}")
        
        return 0
    
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return 1


async def handle_interactive_mode(args):
    """
    ëŒ€í™”í˜• ëª¨ë“œë¡œ ì§ˆë¬¸ ì—°êµ¬ ìˆ˜í–‰
    """
    print("\n" + "=" * 50)
    print("ğŸ¤– ê·¼ìœ¡ ê´€ë ¨ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì—°êµ¬ ì‹œìŠ¤í…œ - ëŒ€í™”í˜• ëª¨ë“œ")
    print("=" * 50)
    print("ğŸ“ ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  Enter í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”")
    print("ğŸ“ 'exit' ë˜ëŠ” 'quit'ì„ ì…ë ¥í•˜ë©´ ì¢…ë£Œí•©ë‹ˆë‹¤")
    print("=" * 50 + "\n")
    
    # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = OllamaClient(
        model=args.model,
        temperature=args.temperature
    )
    
    # API ê°€ìš©ì„± í™•ì¸
    status = await client.check_availability()
    if status["status"] != "available":
        print(f"âŒ Ollama APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {status.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        return 1
        
    print(f"ğŸš€ {status.get('current_model', client.model)} ëª¨ë¸ ì‚¬ìš© ì¤‘\n")
    
    # ì—°êµ¬ ê´€ë¦¬ì ì´ˆê¸°í™”
    manager = ResearchManager(
        ollama_client=client,
        feedback_depth=args.depth,
        feedback_width=args.width,
        concurrent_research=args.concurrent,
        output_dir=args.output_dir
    )
    
    while True:
        try:
            question = input("ğŸ” ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” > ")
            if not question:
                continue
                
            if question.lower() in ["exit", "quit", "ì¢…ë£Œ", "ë‚˜ê°€ê¸°"]:
                print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤")
                break
                
            # ì—°êµ¬ ìˆ˜í–‰
            start_time = datetime.now()
            result = await manager.research_question(question)
            elapsed = (datetime.now() - start_time).total_seconds()
            
            # ê²°ê³¼ ì¶œë ¥
            if "error" in result:
                print(f"âŒ ì—°êµ¬ ì‹¤íŒ¨: {result['error']}")
                continue
                
            print(f"\nâœ… ì—°êµ¬ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ)")
            print(f"ğŸ“Š í’ˆì§ˆ ì ìˆ˜: {result.get('score', 'N/A')}/10")
            print(f"ğŸ”„ í”¼ë“œë°± ë£¨í”„: {result.get('feedback_loops', 'N/A')}íšŒ")
            print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {manager.file_storage.get_session_directory(manager.session_id)}\n")
            
            # ê²°ê³¼ ìš”ì•½ í‘œì‹œ
            if args.show_summary:
                answer = result.get("answer", "")
                print("\n" + "=" * 50)
                print("ğŸ“ ì—°êµ¬ ê²°ê³¼ ìš”ì•½ (ì²˜ìŒ 500ì)")
                print("=" * 50)
                print(answer[:500] + "...\n")
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤")
            break
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    return 0


async def main():
    # ìƒìœ„ ìˆ˜ì¤€ íŒŒì„œ ìƒì„±
    parser = argparse.ArgumentParser(
        description='ê·¼ìœ¡ ê´€ë ¨ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì—°êµ¬ ì‹œìŠ¤í…œ CLI',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    # ê³µí†µ ì¸ì
    parser.add_argument('--model', '-m', type=str, default='gemma3:4b',
                      help='ì‚¬ìš©í•  Ollama ëª¨ë¸')
    parser.add_argument('--output-dir', '-o', type=str, default='./research_outputs',
                      help='ì—°êµ¬ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--temperature', '-t', type=float, default=0.7,
                      help='ìƒì„± ì˜¨ë„ (0.1~1.0, ë†’ì„ìˆ˜ë¡ ì°½ì˜ì )')
    parser.add_argument('--depth', '-d', type=int, default=2,
                      help='í”¼ë“œë°± ë£¨í”„ ê¹Šì´ (1-10)')
    parser.add_argument('--width', '-w', type=int, default=2,
                      help='í”¼ë“œë°± ë£¨í”„ ë„ˆë¹„ (1-10)')
    parser.add_argument('--concurrent', '-c', type=int, default=2,
                      help='ë™ì‹œ ì²˜ë¦¬í•  ìµœëŒ€ ì§ˆë¬¸ ìˆ˜')
    parser.add_argument('--show-summary', '-s', action='store_true',
                      help='ì‘ë‹µ ìš”ì•½ í‘œì‹œ')
    parser.add_argument('--version', '-v', action='version',
                      version=f'ê·¼ìœ¡ ê´€ë ¨ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì—°êµ¬ ì‹œìŠ¤í…œ v{VERSION}')
    
    # ì„œë¸ŒíŒŒì„œ ì„¤ì •
    subparsers = parser.add_subparsers(dest='command', help='ëª…ë ¹ì–´')
    
    # ë‹¨ì¼ ì§ˆë¬¸ ëª…ë ¹ì–´
    question_parser = subparsers.add_parser('question', help='ë‹¨ì¼ ì§ˆë¬¸ ì—°êµ¬')
    question_parser.add_argument('question', type=str, help='ì—°êµ¬í•  ì§ˆë¬¸')
    
    # íŒŒì¼ ê¸°ë°˜ ì§ˆë¬¸ ëª…ë ¹ì–´
    file_parser = subparsers.add_parser('file', help='íŒŒì¼ì—ì„œ ì§ˆë¬¸ ë¡œë“œ ë° ì—°êµ¬')
    file_parser.add_argument('file', type=str, help='ì§ˆë¬¸ì´ í¬í•¨ëœ íŒŒì¼ (í…ìŠ¤íŠ¸ ë˜ëŠ” JSON)')
    
    # ëŒ€í™”í˜• ëª¨ë“œ ëª…ë ¹ì–´
    interactive_parser = subparsers.add_parser('interactive', help='ëŒ€í™”í˜• ëª¨ë“œ')
    
    # ì¸ì íŒŒì‹±
    args = parser.parse_args()
    
    # ëª…ë ¹ì–´ì— ë”°ë¼ ì²˜ë¦¬
    if args.command == 'question':
        return await handle_single_question(args)
    elif args.command == 'file':
        return await handle_questions_file(args)
    elif args.command == 'interactive':
        return await handle_interactive_mode(args)
    else:
        parser.print_help()
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
